{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "894c26c3-2f96-4a07-8ca4-a119c15a917c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-19T21:32:30.884197Z",
     "iopub.status.busy": "2025-09-19T21:32:30.884120Z",
     "iopub.status.idle": "2025-09-19T21:32:30.975842Z",
     "shell.execute_reply": "2025-09-19T21:32:30.975279Z",
     "shell.execute_reply.started": "2025-09-19T21:32:30.884188Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded:\n",
      "   Model API: http://127.0.0.1:8080\n",
      "   Model: Meta-Llama-3-8B-Instruct_Q4_K_M.gguf\n",
      "   Default Max Sources: 5\n"
     ]
    }
   ],
   "source": [
    "########################################################################################################################\n",
    "# What it does: Sets up a local AI assistant that runs entirely on your own computer, \n",
    "#         with built-in research capabilities for ArXiv and Wikipedia searches.\n",
    "# Key Benefits:\n",
    "#        Complete Privacy: No data leaves your machine - perfect for sensitive competitive intelligence work\n",
    "#        Zero API Costs: No per-query charges like ChatGPT/Claude\n",
    "#        Research-Ready: Automatically finds and cites academic papers and references\n",
    "#        Enterprise-Safe: Meets security requirements for handling proprietary information\n",
    "# Core Value: This gives you the power of ChatGPT-level AI for your sales enablement and competitive analysis work, \n",
    "#        but with complete data control and no ongoing costs - exactly what Anaconda's enterprise customers need.\n",
    "#######################################################################################################################\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import asyncio\n",
    "import time\n",
    "import logging\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "from typing import List, Optional, Dict, Any\n",
    "from IPython.display import display, Markdown, HTML\n",
    "\n",
    "@dataclass\n",
    "class LocalSettings:\n",
    "    MODEL_API_URL: str = \"http://127.0.0.1:8080\"\n",
    "    MODEL_NAME: str = \"Meta-Llama-3-8B-Instruct_Q4_K_M.gguf\"\n",
    "    TEMPERATURE: float = 0.3\n",
    "    MAX_TOKENS: int = 1500\n",
    "    MAX_CONTEXT_LENGTH: int = 4096\n",
    "    TOP_P: float = 0.9\n",
    "    TOP_K: int = 40\n",
    "    REPEAT_PENALTY: float = 1.1\n",
    "    ENABLE_ARXIV: bool = True\n",
    "    ENABLE_WIKIPEDIA: bool = True\n",
    "    MAX_SEARCH_RESULTS: int = 10\n",
    "    MAX_SOURCES_PER_QUERY: int = 7\n",
    "    REQUESTS_PER_MINUTE: int = 20\n",
    "    DEFAULT_CITATION_STYLE: str = \"apa\"\n",
    "    DEFAULT_MAX_SOURCES: int = 5\n",
    "\n",
    "settings = LocalSettings()\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"   Model API: {settings.MODEL_API_URL}\")\n",
    "print(f\"   Model: {settings.MODEL_NAME}\")\n",
    "print(f\"   Default Max Sources: {settings.DEFAULT_MAX_SOURCES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa547772-8c09-405f-98ff-58971b37104d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-19T21:32:30.976529Z",
     "iopub.status.busy": "2025-09-19T21:32:30.976416Z",
     "iopub.status.idle": "2025-09-19T21:32:30.997473Z",
     "shell.execute_reply": "2025-09-19T21:32:30.996965Z",
     "shell.execute_reply.started": "2025-09-19T21:32:30.976519Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Connected to your local Llama 3 model API!\n",
      "   Model: Meta-Llama-3-8B-Instruct_Q4_K_M.gguf\n",
      "   Server: http://127.0.0.1:8080\n"
     ]
    }
   ],
   "source": [
    "############################################################################################################################\n",
    "# What it does: Creates a LocalLLM class that connects to and manages your local Llama 3 AI model, \n",
    "#        with specialized methods for research tasks like generating summaries and evaluating source relevance.\n",
    "# Key Benefits:\n",
    "#      Plug-and-Play: Automatically detects and connects to your local AI model with health checks\n",
    "#      Research-Optimized: Built-in functions for creating research reports and ranking source quality\n",
    "#      Robust Fallbacks: Continues working even if the AI model goes offline (uses keyword matching)\n",
    "#      Multiple API Support: Tries different endpoints to ensure compatibility with various local AI setups\n",
    "# Core Value: This is the \"brain\" of your local AI system - it handles all the technical complexity of talking to your \n",
    "#      local model so you can focus on getting research insights for competitive intelligence and sales enablement without \n",
    "#      worrying about API failures or connection issues.\n",
    "# Essentially, it makes your local AI as reliable and easy to use as a cloud service, but with complete data privacy.\n",
    "############################################################################################################################\n",
    "\n",
    "\n",
    "class LocalLLM:\n",
    "    def __init__(self):\n",
    "        self.api_url = settings.MODEL_API_URL\n",
    "        self.model_name = settings.MODEL_NAME\n",
    "        self.model_loaded = False\n",
    "        self._test_connection()\n",
    "        \n",
    "    def _test_connection(self):\n",
    "        try:\n",
    "            response = requests.get(f\"{self.api_url}/health\", timeout=5)\n",
    "            if response.status_code == 200:\n",
    "                self.model_loaded = True\n",
    "                print(\"✅ Connected to your local Llama 3 model API!\")\n",
    "                print(f\"   Model: {self.model_name}\")\n",
    "                print(f\"   Server: {self.api_url}\")\n",
    "            else:\n",
    "                print(f\"⚠️  API responded with status: {response.status_code}\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"❌ Could not connect to model API at {self.api_url}\")\n",
    "            print(\"   Make sure your Anaconda AI Navigator model is running\")\n",
    "    \n",
    "    def generate_research_summary(self, query: str, sources_text: str, max_length: int = 1500) -> str:\n",
    "        if not self.model_loaded:\n",
    "            return \"❌ Model API not available. Please start your model in Anaconda AI Navigator.\"\n",
    "        \n",
    "        system_message = \"You are a professional research assistant. Create comprehensive, well-structured research reports.\"\n",
    "        user_prompt = f\"\"\"Research Query: {query}\n",
    "\n",
    "Available Sources:\n",
    "{sources_text}\n",
    "\n",
    "Please create a comprehensive research report that addresses the query directly.\n",
    "\n",
    "Research Report:\"\"\"\n",
    "\n",
    "        return self._generate_response(user_prompt, system_message, max_length)\n",
    "    \n",
    "    def evaluate_source_relevance(self, query: str, source_content: str) -> float:\n",
    "        if not self.model_loaded:\n",
    "            # Keyword matching fallback\n",
    "            query_words = set(query.lower().split())\n",
    "            content_words = set(source_content.lower().split())\n",
    "            overlap = len(query_words.intersection(content_words))\n",
    "            return min(overlap / len(query_words), 1.0) if query_words else 0.0\n",
    "        \n",
    "        system_message = \"Rate source relevance to a query on a scale of 0.0 to 1.0. Respond with ONLY the numerical score.\"\n",
    "        user_prompt = f\"Query: {query}\\nSource: {source_content[:1000]}...\\nRelevance Score:\"\n",
    "        \n",
    "        try:\n",
    "            response = self._generate_response(user_prompt, system_message, 50)\n",
    "            import re\n",
    "            match = re.search(r'(\\d+\\.?\\d*)', response)\n",
    "            if match:\n",
    "                score = float(match.group(1))\n",
    "                return max(0.0, min(1.0, score))\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Fallback to keyword matching\n",
    "        query_words = set(query.lower().split())\n",
    "        content_words = set(source_content.lower().split())\n",
    "        overlap = len(query_words.intersection(content_words))\n",
    "        return min(overlap / len(query_words), 1.0) if query_words else 0.0\n",
    "    \n",
    "    def _generate_response(self, prompt: str, system_message: str = None, max_tokens: int = None) -> str:\n",
    "        if not self.model_loaded:\n",
    "            return \"❌ Model API not connected\"\n",
    "        \n",
    "        max_tokens = max_tokens or settings.MAX_TOKENS\n",
    "        \n",
    "        try:\n",
    "            if system_message:\n",
    "                formatted_prompt = f\"<|start_header_id|>system<|end_header_id|>\\n{system_message}<|eot_id|><|start_header_id|>user<|end_header_id|>\\n{prompt}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\n",
    "            else:\n",
    "                formatted_prompt = f\"<|start_header_id|>user<|end_header_id|>\\n{prompt}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\n",
    "            \n",
    "            payload = {\n",
    "                \"prompt\": formatted_prompt,\n",
    "                \"max_tokens\": max_tokens,\n",
    "                \"temperature\": settings.TEMPERATURE,\n",
    "                \"top_p\": settings.TOP_P,\n",
    "                \"top_k\": settings.TOP_K,\n",
    "                \"repeat_penalty\": settings.REPEAT_PENALTY,\n",
    "                \"stop\": [\"<|eot_id|>\", \"<|end_of_text|>\"]\n",
    "            }\n",
    "            \n",
    "            endpoints = [\"/v1/completions\", \"/completions\", \"/generate\", \"/api/generate\"]\n",
    "            \n",
    "            for endpoint in endpoints:\n",
    "                try:\n",
    "                    response = requests.post(\n",
    "                        f\"{self.api_url}{endpoint}\",\n",
    "                        json=payload,\n",
    "                        timeout=60,\n",
    "                        headers={'Content-Type': 'application/json'}\n",
    "                    )\n",
    "                    \n",
    "                    if response.status_code == 200:\n",
    "                        result = response.json()\n",
    "                        if 'choices' in result:\n",
    "                            return result['choices'][0].get('text', '').strip()\n",
    "                        elif 'response' in result:\n",
    "                            return result['response'].strip()\n",
    "                        elif 'generated_text' in result:\n",
    "                            return result['generated_text'].strip()\n",
    "                        elif 'text' in result:\n",
    "                            return result['text'].strip()\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            return \"❌ Could not get response from model API\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            return f\"❌ Error generating response: {str(e)}\"\n",
    "\n",
    "# Initialize LLM\n",
    "llm = LocalLLM()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "927af92f-3780-4b9f-aa76-d329fd0e44bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-19T21:32:30.998140Z",
     "iopub.status.busy": "2025-09-19T21:32:30.998036Z",
     "iopub.status.idle": "2025-09-19T21:32:31.001951Z",
     "shell.execute_reply": "2025-09-19T21:32:31.001388Z",
     "shell.execute_reply.started": "2025-09-19T21:32:30.998130Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data structures defined\n"
     ]
    }
   ],
   "source": [
    "###############################################################################################################################\n",
    "#  What it does: Defines data containers that organize and structure all your research information \n",
    "#          individual sources (papers, articles) and complete research results with citations.\n",
    "# Key Benefits:\n",
    "#         Clean Organization: Each source tracks title, URL, content, relevance score, and publication date in one place\n",
    "#         Quality Scoring: Built-in relevance scoring to rank sources by importance to your query\n",
    "#         Complete Research Packages: Bundles everything together - query, report, sources, citations, and confidence scores\n",
    "#         Easy Tracking: Automatically records research time and maintains citation lists\n",
    "# Core Value: This creates a professional research database structure that turns messy web searches into organized, \n",
    "#        citable research reports - perfect for creating those polished competitive analysis documents and sales battle cards \n",
    "#        that look enterprise-ready.\n",
    "# Think of it as your research filing system that ensures nothing gets lost and everything is properly documented and scored.\n",
    "################################################################################################################################\n",
    "\n",
    "    \n",
    "class Source:\n",
    "    def __init__(self, title, url, content, relevance_score, source_type=\"web\", publish_date=None):\n",
    "        self.title = title\n",
    "        self.url = url\n",
    "        self.content = content\n",
    "        self.relevance_score = relevance_score\n",
    "        self.source_type = source_type\n",
    "        self.publish_date = publish_date\n",
    "\n",
    "@dataclass\n",
    "class ResearchResult:\n",
    "    query: str\n",
    "    report: str\n",
    "    sources: List[Source]\n",
    "    citations: List[str]\n",
    "    confidence_score: float\n",
    "    research_time: float\n",
    "\n",
    "print(\"Data structures defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f97823ce-0ce9-447f-89de-6ba8f8adfbde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-19T21:32:31.002496Z",
     "iopub.status.busy": "2025-09-19T21:32:31.002400Z",
     "iopub.status.idle": "2025-09-19T21:32:31.121724Z",
     "shell.execute_reply": "2025-09-19T21:32:31.121387Z",
     "shell.execute_reply.started": "2025-09-19T21:32:31.002486Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ arXiv academic search available\n",
      "✅ Wikipedia search available\n"
     ]
    }
   ],
   "source": [
    "###############################################################################################################################\n",
    "# What it does: Creates a multi-source search engine that simultaneously queries arXiv (academic papers) and Wikipedia, \n",
    "#      then combines results into structured, deduplicated source lists.\n",
    "# Key Benefits:\n",
    "#      Dual-Source Power: Gets both cutting-edge academic research AND accessible explanations in one search\n",
    "#      Bulletproof Design: Automatically detects available search engines and gracefully handles failures\n",
    "#      Fast Performance: Uses async searching to query multiple sources simultaneously\n",
    "#      Clean Results: Removes duplicates and returns properly structured data ready for analysis\n",
    "# Core Value: This gives you comprehensive research coverage for your competitive intelligence work,\n",
    "#      academic papers for technical depth (perfect for understanding new AI/ML developments that competitors might be using) \n",
    "#      plus Wikipedia for context and background.\n",
    "# Essential for creating those detailed technical battle cards where you need both the latest research insights and \n",
    "#     clear explanations that sales teams can actually use.\n",
    "#################################################################################################################################\n",
    "                                                                                                                                                                                                                             \n",
    "                                                                                                                                                                                                                             \n",
    "class SearchTool:\n",
    "    def __init__(self):\n",
    "        self.engines = {}\n",
    "        self._check_available_engines()\n",
    "    \n",
    "    def _check_available_engines(self):\n",
    "        try:\n",
    "            import arxiv\n",
    "            self.engines['arxiv'] = True\n",
    "            print(\"✅ arXiv academic search available\")\n",
    "        except ImportError:\n",
    "            self.engines['arxiv'] = False\n",
    "            print(\"⚠️  arXiv not available\")\n",
    "        \n",
    "        try:\n",
    "            import wikipedia\n",
    "            self.engines['wikipedia'] = True\n",
    "            print(\"✅ Wikipedia search available\")\n",
    "        except ImportError:\n",
    "            self.engines['wikipedia'] = False\n",
    "            print(\"⚠️  Wikipedia not available\")\n",
    "    \n",
    "    async def search(self, query: str, max_results: int = 10) -> List[Source]:\n",
    "        print(f\"🔍 Searching for: {query}\")\n",
    "        all_sources = []\n",
    "        \n",
    "        if self.engines.get('arxiv') and settings.ENABLE_ARXIV:\n",
    "            academic_sources = await self._search_arxiv(query, max_results // 2)\n",
    "            all_sources.extend(academic_sources)\n",
    "        \n",
    "        if self.engines.get('wikipedia') and settings.ENABLE_WIKIPEDIA:\n",
    "            wiki_sources = await self._search_wikipedia(query, max_results // 2)\n",
    "            all_sources.extend(wiki_sources)\n",
    "        \n",
    "        if not all_sources:\n",
    "            print(\"⚠️  No search engines available - using demo data\")\n",
    "            return self._get_demo_sources(query)\n",
    "        \n",
    "        return self._remove_duplicates(all_sources)[:max_results]\n",
    "    \n",
    "    async def _search_arxiv(self, query: str, max_results: int) -> List[Source]:\n",
    "        sources = []\n",
    "        try:\n",
    "            import arxiv\n",
    "            client = arxiv.Client()\n",
    "            search = arxiv.Search(query=query, max_results=max_results, sort_by=arxiv.SortCriterion.Relevance)\n",
    "            \n",
    "            for paper in client.results(search):\n",
    "                source = Source(\n",
    "                    title=paper.title,\n",
    "                    url=paper.entry_id,\n",
    "                    content=paper.summary,\n",
    "                    relevance_score=0.9,\n",
    "                    source_type=\"academic\",\n",
    "                    publish_date=paper.published.strftime(\"%Y-%m-%d\") if paper.published else None\n",
    "                )\n",
    "                sources.append(source)\n",
    "            \n",
    "            print(f\"   ✅ Found {len(sources)} academic papers\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Academic search failed: {e}\")\n",
    "        \n",
    "        return sources\n",
    "    \n",
    "    async def _search_wikipedia(self, query: str, max_results: int) -> List[Source]:\n",
    "        sources = []\n",
    "        try:\n",
    "            import wikipedia\n",
    "            search_results = wikipedia.search(query, results=max_results)\n",
    "            \n",
    "            for title in search_results:\n",
    "                try:\n",
    "                    page = wikipedia.page(title)\n",
    "                    source = Source(\n",
    "                        title=page.title,\n",
    "                        url=page.url,\n",
    "                        content=page.summary,\n",
    "                        relevance_score=0.7,\n",
    "                        source_type=\"encyclopedia\"\n",
    "                    )\n",
    "                    sources.append(source)\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            print(f\"   ✅ Found {len(sources)} Wikipedia articles\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Wikipedia search failed: {e}\")\n",
    "        \n",
    "        return sources\n",
    "    \n",
    "    def _get_demo_sources(self, query: str) -> List[Source]:\n",
    "        return [\n",
    "            Source(\n",
    "                title=f\"Introduction to {query}\",\n",
    "                url=\"https://demo.example.com/intro\",\n",
    "                content=f\"This is an introductory overview of {query}. This demo content shows what real research sources would look like.\",\n",
    "                relevance_score=0.7,\n",
    "                source_type=\"web\"\n",
    "            )\n",
    "        ]\n",
    "    \n",
    "    def _remove_duplicates(self, sources: List[Source]) -> List[Source]:\n",
    "        seen_urls = set()\n",
    "        unique_sources = []\n",
    "        \n",
    "        for source in sources:\n",
    "            if source.url not in seen_urls:\n",
    "                seen_urls.add(source.url)\n",
    "                unique_sources.append(source)\n",
    "        \n",
    "        return unique_sources\n",
    "\n",
    "search_tool = SearchTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a298a47-aa01-46df-8abd-a57617e9be86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-19T21:32:31.123776Z",
     "iopub.status.busy": "2025-09-19T21:32:31.123546Z",
     "iopub.status.idle": "2025-09-19T21:32:31.134193Z",
     "shell.execute_reply": "2025-09-19T21:32:31.133617Z",
     "shell.execute_reply.started": "2025-09-19T21:32:31.123766Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research Agent initialized and ready!\n"
     ]
    }
   ],
   "source": [
    "###################################################################################################################################################\n",
    "# What it does: The main research orchestrator that runs a complete research pipeline, searches multiple sources, evaluates quality, \n",
    "#      generates professional reports with citations, and provides confidence scoring.\n",
    "# Key Benefits:\n",
    "#     Fully Automated: Takes a simple query and delivers a complete research report with zero manual work\n",
    "#     Quality Control: Automatically ranks sources by relevance and selects only the best ones\n",
    "#     Professional Output: Generates properly cited reports with confidence scores for credibility\n",
    "#     Bulletproof Reliability: Multiple fallback systems ensure you always get results even if components fail\n",
    "#     Research Memory: Tracks all past research for easy reference and follow-up analysis\n",
    "# Core Value: This is your one-click competitive intelligence generator - just ask a question like \"What are Anaconda's latest security features?\" \n",
    "#     and get back a professional research report with academic sources, Wikipedia context, proper citations, and a confidence score.\n",
    "# Perfect for rapidly creating those detailed competitive battle cards and technical analysis documents that would normally \n",
    "#     take hours of manual research.\n",
    "#####################################################################################################################################################\n",
    "\n",
    "\n",
    "class ResearchAgent:\n",
    "    def __init__(self):\n",
    "        self.llm = llm\n",
    "        self.search_tool = search_tool\n",
    "        self.research_history = []\n",
    "        print(\"Research Agent initialized and ready!\")\n",
    "    \n",
    "    async def research(self, query: str, max_sources: int = None) -> ResearchResult:\n",
    "        start_time = time.time()\n",
    "        max_sources = max_sources or settings.DEFAULT_MAX_SOURCES\n",
    "        \n",
    "        print(f\"\\nStarting research on: {query}\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        try:\n",
    "            # Step 1: Search for sources\n",
    "            print(\"Step 1: Searching for sources...\")\n",
    "            sources = await self.search_tool.search(query, max_sources)\n",
    "            \n",
    "            if not sources:\n",
    "                return ResearchResult(\n",
    "                    query=query,\n",
    "                    report=\"❌ No sources found for this query.\",\n",
    "                    sources=[],\n",
    "                    citations=[],\n",
    "                    confidence_score=0.0,\n",
    "                    research_time=time.time() - start_time\n",
    "                )\n",
    "            \n",
    "            print(f\"   Found {len(sources)} sources\")\n",
    "            \n",
    "            # Step 2: Evaluate relevance\n",
    "            print(\"Step 2: Evaluating source relevance...\")\n",
    "            for i, source in enumerate(sources):\n",
    "                print(f\"   Evaluating source {i+1}/{len(sources)}...\")\n",
    "                if self.llm.model_loaded:\n",
    "                    try:\n",
    "                        relevance = self.llm.evaluate_source_relevance(query, source.content)\n",
    "                        source.relevance_score = relevance\n",
    "                    except:\n",
    "                        pass\n",
    "            \n",
    "            # Step 3: Filter best sources\n",
    "            best_sources = sorted(sources, key=lambda s: s.relevance_score, reverse=True)[:max_sources]\n",
    "            print(f\"   Selected {len(best_sources)} high-quality sources\")\n",
    "            \n",
    "            # Step 4: Generate report\n",
    "            print(\"Step 3: Generating research report...\")\n",
    "            report = await self._generate_report(query, best_sources)\n",
    "            \n",
    "            # Step 5: Generate citations\n",
    "            print(\"Step 4: Creating citations...\")\n",
    "            citations = self._generate_citations(best_sources)\n",
    "            \n",
    "            # Step 6: Calculate confidence\n",
    "            confidence = self._calculate_confidence(best_sources)\n",
    "            research_time = time.time() - start_time\n",
    "            \n",
    "            result = ResearchResult(\n",
    "                query=query,\n",
    "                report=report,\n",
    "                sources=best_sources,\n",
    "                citations=citations,\n",
    "                confidence_score=confidence,\n",
    "                research_time=research_time\n",
    "            )\n",
    "            \n",
    "            self.research_history.append(result)\n",
    "            \n",
    "            print(f\"✅ Research completed in {research_time:.1f} seconds\")\n",
    "            print(f\"   Confidence Score: {confidence:.2f}\")\n",
    "            print(\"=\" * 50)\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Research failed: {e}\")\n",
    "            return ResearchResult(\n",
    "                query=query,\n",
    "                report=f\"❌ Research failed due to error: {str(e)}\",\n",
    "                sources=[],\n",
    "                citations=[],\n",
    "                confidence_score=0.0,\n",
    "                research_time=time.time() - start_time\n",
    "            )\n",
    "    \n",
    "    async def _generate_report(self, query: str, sources: List[Source]) -> str:\n",
    "        if not sources:\n",
    "            return \"No sources available to generate report.\"\n",
    "        \n",
    "        sources_text = \"\"\n",
    "        for i, source in enumerate(sources, 1):\n",
    "            sources_text += f\"\\nSource {i} - {source.title} ({source.source_type}):\\n\"\n",
    "            sources_text += f\"{source.content[:1000]}...\\n\"\n",
    "            sources_text += f\"URL: {source.url}\\n\"\n",
    "            sources_text += \"-\" * 40 + \"\\n\"\n",
    "        \n",
    "        if self.llm.model_loaded:\n",
    "            try:\n",
    "                report = self.llm.generate_research_summary(query, sources_text)\n",
    "                return report\n",
    "            except Exception as e:\n",
    "                print(f\"   ⚠️  LLM report generation failed: {e}\")\n",
    "        \n",
    "        # Fallback: Simple summary\n",
    "        fallback_report = f\"# Research Report: {query}\\n\\n\"\n",
    "        fallback_report += f\"Based on {len(sources)} sources, here are the key findings:\\n\\n\"\n",
    "        \n",
    "        for i, source in enumerate(sources, 1):\n",
    "            fallback_report += f\"## Finding {i}: {source.title}\\n\"\n",
    "            fallback_report += f\"**Source:** {source.source_type.title()}\\n\"\n",
    "            fallback_report += f\"**Relevance:** {source.relevance_score:.2f}\\n\\n\"\n",
    "            fallback_report += f\"{source.content[:500]}...\\n\\n\"\n",
    "        \n",
    "        return fallback_report\n",
    "    \n",
    "    def _generate_citations(self, sources: List[Source]) -> List[str]:\n",
    "        citations = []\n",
    "        for source in sources:\n",
    "            if source.source_type == \"academic\":\n",
    "                citation = f\"{source.title}. arXiv. Retrieved from {source.url}\"\n",
    "            elif source.source_type == \"encyclopedia\":\n",
    "                citation = f\"{source.title}. Wikipedia. Retrieved from {source.url}\"\n",
    "            else:\n",
    "                citation = f\"{source.title}. Retrieved from {source.url}\"\n",
    "            citations.append(citation)\n",
    "        return citations\n",
    "    \n",
    "    def _calculate_confidence(self, sources: List[Source]) -> float:\n",
    "        if not sources:\n",
    "            return 0.0\n",
    "        \n",
    "        avg_relevance = sum(s.relevance_score for s in sources) / len(sources)\n",
    "        source_types = len(set(s.source_type for s in sources))\n",
    "        diversity_score = min(source_types / 3.0, 1.0)\n",
    "        count_score = min(len(sources) / 5.0, 1.0)\n",
    "        academic_count = sum(1 for s in sources if s.source_type == \"academic\")\n",
    "        academic_bonus = min(academic_count / len(sources), 0.2)\n",
    "        \n",
    "        confidence = (avg_relevance * 0.4 + diversity_score * 0.2 + count_score * 0.2 + academic_bonus * 0.2)\n",
    "        return min(confidence, 1.0)\n",
    "    \n",
    "    def get_research_history(self) -> List[ResearchResult]:\n",
    "        return self.research_history.copy()\n",
    "\n",
    "agent = ResearchAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45417002-9eaf-4b5f-befd-4fff3ffefa32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-19T21:32:31.134681Z",
     "iopub.status.busy": "2025-09-19T21:32:31.134583Z",
     "iopub.status.idle": "2025-09-19T21:32:31.139496Z",
     "shell.execute_reply": "2025-09-19T21:32:31.139141Z",
     "shell.execute_reply.started": "2025-09-19T21:32:31.134671Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display functions ready!\n"
     ]
    }
   ],
   "source": [
    "###############################################################################################################################\n",
    "# What it does: Creates professional display functions that format your research results with styled HTML output, \n",
    "#       organized sections, and clickable links - perfect for Jupyter notebooks.\n",
    "# Key Benefits:\n",
    "#       Executive-Ready Presentation: Transforms raw data into polished, professional reports with proper formatting\n",
    "#       Easy Scanning: Color-coded sections, clear headings, and an organized layout for quick information absorption\n",
    "#       Clickable Sources: Direct links to all source materials for easy verification and follow-up\n",
    "#       System Monitoring: Real-time status dashboard showing what's working and what's not\n",
    "# Core Value: This turns your research output into screenshot-ready competitive intelligence reports that you can immediately \n",
    "#       drop into presentations, battle cards, or share with sales teams.\n",
    "# No more messy text dumps - everything looks like it came from a professional research firm, complete with confidence scores \n",
    "#       and proper source attribution that builds credibility with stakeholders.\n",
    "#################################################################################################################################\n",
    "\n",
    "\n",
    "def display_research_result(result: ResearchResult):\n",
    "    # Research Summary\n",
    "    summary_html = f\"\"\"\n",
    "    <div style=\"background: #f8f9fa; padding: 20px; border-radius: 10px; margin: 20px 0; border-left: 4px solid #007bff;\">\n",
    "        <h3 style=\"color: #007bff; margin-bottom: 15px;\">Research Summary</h3>\n",
    "        <p><strong>Query:</strong> {result.query}</p>\n",
    "        <p><strong>Research Time:</strong> {result.research_time:.1f} seconds</p>\n",
    "        <p><strong>Confidence Score:</strong> {result.confidence_score:.2f}/1.0</p>\n",
    "        <p><strong>Sources Found:</strong> {len(result.sources)}</p>\n",
    "        <p><strong>Completed:</strong> {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}</p>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    display(HTML(summary_html))\n",
    "    \n",
    "    # Research Report\n",
    "    display(Markdown(\"## Research Report\"))\n",
    "    display(Markdown(result.report))\n",
    "    \n",
    "    # Sources\n",
    "    if result.sources:\n",
    "        display(Markdown(f\"## Sources ({len(result.sources)})\"))\n",
    "        for i, source in enumerate(result.sources, 1):\n",
    "            source_html = f\"\"\"\n",
    "            <div style=\"background: #f8f9fa; padding: 15px; border-radius: 8px; margin: 10px 0; border-left: 4px solid #28a745;\">\n",
    "                <h4 style=\"color: #333; margin-bottom: 5px;\">{i}. {source.title}</h4>\n",
    "                <p style=\"color: #666; font-size: 14px; margin: 5px 0;\">\n",
    "                    <strong>Type:</strong> {source.source_type.title()} | \n",
    "                    <strong>Relevance:</strong> {source.relevance_score:.2f} | \n",
    "                    <a href=\"{source.url}\" target=\"_blank\">View Source</a>\n",
    "                </p>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "            display(HTML(source_html))\n",
    "    \n",
    "    # Citations\n",
    "    if result.citations:\n",
    "        display(Markdown(\"## Citations\"))\n",
    "        for i, citation in enumerate(result.citations, 1):\n",
    "            display(Markdown(f\"{i}. {citation}\"))\n",
    "\n",
    "def show_system_status():\n",
    "    status_html = f\"\"\"\n",
    "    <div style=\"background: #f8f9fa; padding: 20px; border-radius: 10px; margin: 20px 0;\">\n",
    "        <h3 style=\"color: #333; margin-bottom: 15px;\">System Status</h3>\n",
    "        <p><strong>LLM Connected:</strong> {'✅ Yes' if llm.model_loaded else '❌ No'}</p>\n",
    "        <p><strong>arXiv Search:</strong> {'✅ Available' if search_tool.engines.get('arxiv') else '❌ Not Available'}</p>\n",
    "        <p><strong>Wikipedia Search:</strong> {'✅ Available' if search_tool.engines.get('wikipedia') else '❌ Not Available'}</p>\n",
    "        <p><strong>Model API:</strong> {settings.MODEL_API_URL}</p>\n",
    "        <p><strong> Model:</strong> {settings.MODEL_NAME}</p>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    display(HTML(status_html))\n",
    "\n",
    "print(\"Display functions ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42c76d26-7c95-4a99-893b-270834764fad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-19T21:32:31.140155Z",
     "iopub.status.busy": "2025-09-19T21:32:31.140049Z",
     "iopub.status.idle": "2025-09-19T21:33:18.238108Z",
     "shell.execute_reply": "2025-09-19T21:33:18.237700Z",
     "shell.execute_reply.started": "2025-09-19T21:32:31.140145Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Researching: machine learning transformers\n",
      "\n",
      "Starting research on: machine learning transformers\n",
      "==================================================\n",
      "Step 1: Searching for sources...\n",
      "🔍 Searching for: machine learning transformers\n",
      "   ❌ Academic search failed: Page request resulted in HTTP 301: None (http://export.arxiv.org/api/query?search_query=machine+learning+transformers&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=2)\n",
      "   ✅ Found 2 Wikipedia articles\n",
      "   Found 2 sources\n",
      "Step 2: Evaluating source relevance...\n",
      "   Evaluating source 1/2...\n",
      "   Evaluating source 2/2...\n",
      "   Selected 2 high-quality sources\n",
      "Step 3: Generating research report...\n",
      "Step 4: Creating citations...\n",
      "✅ Research completed in 47.1 seconds\n",
      "   Confidence Score: 0.50\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"background: #f8f9fa; padding: 20px; border-radius: 10px; margin: 20px 0; border-left: 4px solid #007bff;\">\n",
       "        <h3 style=\"color: #007bff; margin-bottom: 15px;\">Research Summary</h3>\n",
       "        <p><strong>Query:</strong> machine learning transformers</p>\n",
       "        <p><strong>Research Time:</strong> 47.1 seconds</p>\n",
       "        <p><strong>Confidence Score:</strong> 0.50/1.0</p>\n",
       "        <p><strong>Sources Found:</strong> 2</p>\n",
       "        <p><strong>Completed:</strong> 2025-09-19 16:33:18</p>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Research Report"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Title:** An Exploration of Machine Learning Transformers and Attention Mechanisms\n",
       "\n",
       "**Abstract:**\n",
       "This report provides an in-depth analysis of machine learning transformers, a neural network architecture that has gained significant attention in recent years. We will delve into the concept of transformers, their advantages over traditional recurrent neural networks (RNNs), and the role of attention mechanisms in this architecture.\n",
       "\n",
       "**Introduction:**\n",
       "Machine learning transformers have revolutionized the field of natural language processing by enabling parallel processing and reducing training time. The transformer architecture was first proposed in the 2017 paper \"Attention Is All You Need\" by researchers at Google. This report aims to provide a comprehensive overview of machine learning transformers, their components, and the attention mechanism that underlies their functionality.\n",
       "\n",
       "**Transformer Architecture:**\n",
       "A transformer is a neural network architecture based on the multi-head attention mechanism (Source 1). The architecture consists of an encoder and a decoder. The encoder converts text into numerical representations called tokens, which are then converted into vectors via lookup from a word embedding table. Each token is contextualized within the scope of the context window with other (unmasked) tokens via a parallel multi-head attention mechanism.\n",
       "\n",
       "The transformer architecture has several advantages over traditional RNNs:\n",
       "\n",
       "1. **Parallel Processing:** Transformers can process input sequences in parallel, reducing training time and making them more efficient than RNNs.\n",
       "2. **No Recurrent Units:** Unlike RNNs, transformers do not require recurrent units, which reduces the complexity of the model and makes it easier to train.\n",
       "\n",
       "**Attention Mechanism:**\n",
       "The attention mechanism is a key component of the transformer architecture (Source 2). It determines the importance of each component in a sequence relative to the other components. In natural language processing, this means assigning \"soft\" weights to each word in a sentence based on its relevance to the context.\n",
       "\n",
       "The attention mechanism has several benefits:\n",
       "\n",
       "1. **Contextualization:** Attention allows tokens to be contextualized within the scope of the context window, enabling the model to capture long-range dependencies.\n",
       "2. **Weighted Summation:** The attention mechanism enables the model to compute a weighted sum of token embeddings, which improves the accuracy of the model.\n",
       "\n",
       "**Conclusion:**\n",
       "Machine learning transformers have revolutionized the field of natural language processing by providing a parallel and efficient architecture for processing sequential data. The attention mechanism is a key component of this architecture, enabling the model to capture long-range dependencies and contextualize tokens within the scope of the context window. This report provides a comprehensive overview of machine learning transformers and their components, highlighting their advantages over traditional RNNs.\n",
       "\n",
       "**Recommendations:**\n",
       "Future research should focus on exploring new applications of machine learning transformers, such as image processing and speech recognition. Additionally, researchers should investigate ways to improve the attention mechanism, such as incorporating external knowledge or using more advanced attention techniques.\n",
       "\n",
       "**References:**\n",
       "\n",
       "1. \"Transformer (deep learning architecture)\" (Source 1)\n",
       "2. \"Attention (machine learning)\" (Source 2)\n",
       "\n",
       "**Appendices:**\n",
       "* Additional information on transformer architectures and their applications\n",
       "* Code snippets for implementing transformers in popular machine learning frameworks"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Sources (2)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div style=\"background: #f8f9fa; padding: 15px; border-radius: 8px; margin: 10px 0; border-left: 4px solid #28a745;\">\n",
       "                <h4 style=\"color: #333; margin-bottom: 5px;\">1. Transformer (deep learning architecture)</h4>\n",
       "                <p style=\"color: #666; font-size: 14px; margin: 5px 0;\">\n",
       "                    <strong>Type:</strong> Encyclopedia | \n",
       "                    <strong>Relevance:</strong> 0.95 | \n",
       "                    <a href=\"https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)\" target=\"_blank\">View Source</a>\n",
       "                </p>\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div style=\"background: #f8f9fa; padding: 15px; border-radius: 8px; margin: 10px 0; border-left: 4px solid #28a745;\">\n",
       "                <h4 style=\"color: #333; margin-bottom: 5px;\">2. Attention (machine learning)</h4>\n",
       "                <p style=\"color: #666; font-size: 14px; margin: 5px 0;\">\n",
       "                    <strong>Type:</strong> Encyclopedia | \n",
       "                    <strong>Relevance:</strong> 0.80 | \n",
       "                    <a href=\"https://en.wikipedia.org/wiki/Attention_(machine_learning)\" target=\"_blank\">View Source</a>\n",
       "                </p>\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Citations"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "1. Transformer (deep learning architecture). Wikipedia. Retrieved from https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "2. Attention (machine learning). Wikipedia. Retrieved from https://en.wikipedia.org/wiki/Attention_(machine_learning)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#########################################################################################################################\n",
    "# What it does: Executes the complete research pipeline - runs your query through the entire system and displays \n",
    "#      the final formatted research report with sources, citations, and confidence scores.\n",
    "# Key Benefits:\n",
    "#      One-Click Research: Single command generates a complete competitive intelligence report\n",
    "#      Customizable Scope: Easily adjust the number of sources to control depth vs. speed\n",
    "#      Immediate Results: Async execution provides fast turnaround for time-sensitive analysis\n",
    "#      Ready-to-Share Output: Professional formatting perfect for stakeholder presentations\n",
    "# Core Value: This is your research button - the moment where all the technical complexity disappears and you get \n",
    "#      exactly what you need for competitive analysis: a professional research report on any topic \n",
    "#      (like \"Anaconda's security features\" or \"enterprise Python governance trends\") in seconds instead of hours.\n",
    "# Perfect for those urgent competitive intelligence requests where you need credible, cited analysis fast\n",
    "##########################################################################################################################\n",
    "\n",
    "\n",
    "RESEARCH_QUERY = \"machine learning transformers\"\n",
    "MAX_SOURCES = 5\n",
    "\n",
    "print(f\"Researching: {RESEARCH_QUERY}\")\n",
    "result = await agent.research(RESEARCH_QUERY, max_sources=MAX_SOURCES)\n",
    "display_research_result(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b033718-7fd7-4d93-8270-0b3084b34a34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-19T21:33:18.239430Z",
     "iopub.status.busy": "2025-09-19T21:33:18.239300Z",
     "iopub.status.idle": "2025-09-19T21:33:18.242824Z",
     "shell.execute_reply": "2025-09-19T21:33:18.242589Z",
     "shell.execute_reply.started": "2025-09-19T21:33:18.239418Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"background: #f8f9fa; padding: 20px; border-radius: 10px; margin: 20px 0;\">\n",
       "        <h3 style=\"color: #333; margin-bottom: 15px;\">System Status</h3>\n",
       "        <p><strong>LLM Connected:</strong> ✅ Yes</p>\n",
       "        <p><strong>arXiv Search:</strong> ✅ Available</p>\n",
       "        <p><strong>Wikipedia Search:</strong> ✅ Available</p>\n",
       "        <p><strong>Model API:</strong> http://127.0.0.1:8080</p>\n",
       "        <p><strong> Model:</strong> Meta-Llama-3-8B-Instruct_Q4_K_M.gguf</p>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#####################################################################################################################################\n",
    "# What it does: Displays a real-time health check dashboard showing the connection status of your local AI model, \n",
    "#     search engines, and system configuration.\n",
    "# Key Benefits:\n",
    "#     Instant Diagnostics: Quickly see what's working and what needs attention\n",
    "#     Troubleshooting Made Easy: Color-coded status indicators pinpoint issues immediately\n",
    "#     System Overview: Shows your current model and API settings at a glance\n",
    "#     Zero Guesswork: Eliminates \"is it working?\" uncertainty before running research\n",
    "# Core Value: This is your system dashboard. It is essential to ensure everything is running smoothly before diving into competitive \n",
    "#     intelligence research. Saves you from wasting time on queries when components are down and gives you confidence that your \n",
    "#     research results are coming from all available sources.\n",
    "# Perfect for quick status checks during demos or when preparing for important research sessions.\n",
    "#######################################################################################################################################\n",
    "\n",
    "\n",
    "show_system_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fde9ec03-3eb5-4eed-8b8b-66f042148138",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-19T21:33:18.243355Z",
     "iopub.status.busy": "2025-09-19T21:33:18.243265Z",
     "iopub.status.idle": "2025-09-19T21:33:18.253038Z",
     "shell.execute_reply": "2025-09-19T21:33:18.252728Z",
     "shell.execute_reply.started": "2025-09-19T21:33:18.243347Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Research History (1 queries)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background: #e8f4f8; padding: 15px; border-radius: 8px; margin: 10px 0; border-left: 4px solid #17a2b8;\">\n",
       "            <h4 style=\"color: #333; margin-bottom: 10px;\">1. machine learning transformers</h4>\n",
       "            <p style=\"color: #666; font-size: 14px; margin: 5px 0;\">\n",
       "                <strong>Confidence:</strong> 0.50 | \n",
       "                <strong>Sources:</strong> 2 | \n",
       "                <strong>Time:</strong> 47.1s\n",
       "            </p>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#########################################################################################################################\n",
    "# What it does: Displays a searchable log of all your previous research queries with key metrics like confidence scores, \n",
    "#     source counts, and processing times in an organized timeline format.\n",
    "# Key Benefits:\n",
    "#     Research Trail: Never lose track of what you've already investigated\n",
    "#     Performance Tracking: See which queries worked best based on confidence scores and source quality\n",
    "#     Time Management: Track how long different types of research take to optimize your workflow\n",
    "#     Easy Reference: Quickly revisit past competitive intelligence without re-running searches\n",
    "# Core Value: This creates your competitive intelligence knowledge base, which enables a permanent record \n",
    "#     of all your research that helps you avoid duplicate work, track investigation patterns, \n",
    "#     and build a comprehensive database of competitive insights over time.\n",
    "# Essential for maintaining institutional knowledge and ensuring you can always reference past analysis when \n",
    "#     building updated battle cards or presenting historical competitive trends to leadership.\n",
    "#########################################################################################################################\n",
    "\n",
    "\n",
    "history = agent.get_research_history()\n",
    "\n",
    "if not history:\n",
    "    print(\"No research history yet. Run a research query first!\")\n",
    "else:\n",
    "    display(Markdown(f\"## Research History ({len(history)} queries)\"))\n",
    "    \n",
    "    for i, result in enumerate(history, 1):\n",
    "        history_html = f\"\"\"\n",
    "        <div style=\"background: #e8f4f8; padding: 15px; border-radius: 8px; margin: 10px 0; border-left: 4px solid #17a2b8;\">\n",
    "            <h4 style=\"color: #333; margin-bottom: 10px;\">{i}. {result.query}</h4>\n",
    "            <p style=\"color: #666; font-size: 14px; margin: 5px 0;\">\n",
    "                <strong>Confidence:</strong> {result.confidence_score:.2f} | \n",
    "                <strong>Sources:</strong> {len(result.sources)} | \n",
    "                <strong>Time:</strong> {result.research_time:.1f}s\n",
    "            </p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        display(HTML(history_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79a0c786-a2cb-4142-8479-b09cf0d2a6db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-19T21:33:18.253593Z",
     "iopub.status.busy": "2025-09-19T21:33:18.253494Z",
     "iopub.status.idle": "2025-09-19T21:33:18.256549Z",
     "shell.execute_reply": "2025-09-19T21:33:18.256256Z",
     "shell.execute_reply.started": "2025-09-19T21:33:18.253584Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /Users/smonroe/research_agent\n",
      "\n",
      "Directory contents:\n",
      "  environment.yml\n",
      "  config\n",
      "  tests\n",
      "  models\n",
      "  logs\n",
      "  environment-ai-agent.yml\n",
      "  .git\n",
      "  main.py\n",
      "  data\n",
      "  outputs\n",
      "  sam_web_interface.py\n",
      "  research_agent\n",
      "  conda-spec.txt\n",
      "  src\n"
     ]
    }
   ],
   "source": [
    "# What it does: Navigates to your research agent project folder and displays all the files and \n",
    "#     directories to confirm you're in the correct location for running the AI research system.\n",
    "# Key Benefits:\n",
    "#     File Path Verification: Ensures you're in the correct directory before running any code\n",
    "#     Environment Setup: Prevents \"file not found\" errors when accessing project files\n",
    "#     Project Overview: Shows all available files and components at a glance\n",
    "#     Debugging Aid: Helps troubleshoot path-related issues quickly\n",
    "# Core Value: This is your project initialization checkpoint - essential for ensuring your local AI research system \n",
    "#     can locate all its components (models, configuration files, data) before you begin any competitive intelligence work.\n",
    "# Think of it as checking your toolkit before starting a job - ensures everything is where it should be, so your research queries run smoothly.\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "# Change to your research_agent directory\n",
    "os.chdir('/Users/smonroe/research_agent')\n",
    "\n",
    "# Verify you're in the right place\n",
    "print(\"Current directory:\", os.getcwd())\n",
    "print(\"\\nDirectory contents:\")\n",
    "for item in os.listdir('.'):\n",
    "    print(f\"  {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54c8f8e4-a174-49f3-b984-425a26ec0459",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-19T21:33:18.257595Z",
     "iopub.status.busy": "2025-09-19T21:33:18.257495Z",
     "iopub.status.idle": "2025-09-19T21:33:20.833921Z",
     "shell.execute_reply": "2025-09-19T21:33:20.832641Z",
     "shell.execute_reply.started": "2025-09-19T21:33:18.257585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Created directories\n",
      " Initializing research agent for web interface...\n",
      "🤖 Initializing Local Research Agent with your Llama 3 model...\n",
      "✅ Connected to your local Llama 3 model API!\n",
      "   Model: Meta-Llama-3-8B-Instruct_Q4_K_M.gguf\n",
      "   Server: http://127.0.0.1:8080\n",
      "✅ Local LLM connected\n",
      "✅ arXiv academic search available\n",
      "✅ Wikipedia search available\n",
      "✅ Search tools initialized\n",
      "Research agent initialized successfully!\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:7861\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Web interface launched at: http://127.0.0.1:7861\n",
      "Interface is local only - not accessible from internet\n",
      "The server runs in the background - you can continue using Jupyter\n",
      "To stop the server, restart the kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [19/Sep/2025 16:33:20] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Sep/2025 16:33:21] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Starting research on: artificial intelligence ethics\n",
      "==================================================\n",
      "📚 Step 1: Searching for sources...\n",
      "🔍 Searching for: artificial intelligence ethics\n",
      "   ❌ Academic search failed: Page request resulted in HTTP 301: This study proposes an analysis of the different types of ethical approaches\n",
      "involved in the ethics of AI, and situates their interests and limits. First,\n",
      "the author introduces to the contemporary need for and meaning of ethics. He\n",
      "distinguishes it from other registers of normativities and underlines its\n",
      "inadequacy to formalization. He then presents a cartography of the landscape of\n",
      "ethical theories covered by moral philosophy, taking care to distinguish\n",
      "meta-ethics, normative ethics and applied ethics. In drawing up this overview,\n",
      "the author questions the relationship between ethics and artificial\n",
      "intelligence. The analysis focuses in particular on the main ethical currents\n",
      "that have imposed themselves in the ways of doing digital ethics and AI in our\n",
      "Western democracies. The author asks whether these practices of ethics, as they\n",
      "seem to crystallize today in a precise pattern, constitute a sufficient and\n",
      "sufficiently satisfactory response to our needs for ethics in AI. The study\n",
      "concludes with a reflection on the reasons why a human ethics of AI based on a\n",
      "pragmatic practice of contextual ethics remains necessary and irreducible to\n",
      "any formalization or automated treatment of the ethical questions that arise\n",
      "for humans. (http://export.arxiv.org/api/query?search_query=artificial+intelligence+ethics&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=1)\n",
      "   ✅ Found 1 Wikipedia articles\n",
      "   Found 1 initial sources\n",
      "🎯 Step 2: Evaluating source relevance...\n",
      "   Evaluating source 1/1: Ethics of artificial intelligence...\n",
      "   Selected 1 high-quality sources\n",
      "📝 Step 3: Generating research report...\n",
      "📖 Step 4: Creating citations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [19/Sep/2025 16:34:34] \"POST /research HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Research completed in 51.2 seconds\n",
      "   Confidence Score: 0.47\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [19/Sep/2025 16:35:02] \"GET /history HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Sep/2025 16:35:05] \"GET /status HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# What it does: Creates a professional web application with a polished browser interface for your local AI research agent, \n",
    "#    complete with tabs for research, status monitoring, and history tracking.\n",
    "# Key Benefits:\n",
    "#     Demo-Ready Interface: Clean, professional design perfect for customer presentations and sales demos\n",
    "#     Zero Setup Required: Automatically launches in your browser from Jupyter with one command\n",
    "#     Multi-Tab Organization: Separate sections for research, system status, history, and documentation\n",
    "#     Sample Query Library: Pre-loaded examples to help users get started quickly\n",
    "#     Real-Time Feedback: Loading indicators, progress updates, and professional result formatting\n",
    "# Core Value: This transforms your technical research system into a client-facing demo tool that showcases \n",
    "#     Anaconda's AI Platform capabilities. Perfect for sales presentations where you need to demonstrate local AI, secure governance, \n",
    "#     and enterprise-ready research capabilities without revealing any underlying complexity.\n",
    "# Essentially, it's your competitive intelligence showcase that is professional enough to present to C-level executives \n",
    "#    while highlighting Anaconda's key differentiators around local deployment, data privacy, and enterprise security.\n",
    "###################################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "from flask import Flask, render_template_string, request, jsonify\n",
    "import asyncio\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "import threading\n",
    "import webbrowser\n",
    "from time import sleep\n",
    "\n",
    "# Fix for Jupyter\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "# Import your research components\n",
    "from src.agent import get_research_agent\n",
    "from config.settings import settings\n",
    "\n",
    "# Create Flask app\n",
    "app = Flask(__name__)\n",
    "research_agent = None\n",
    "\n",
    "def initialize_agent():\n",
    "    global research_agent\n",
    "    if research_agent is None:\n",
    "        try:\n",
    "            research_agent = get_research_agent()\n",
    "            return True, \"Research agent initialized successfully!\"\n",
    "        except Exception as e:\n",
    "            return False, f\"Failed to initialize agent: {str(e)}\"\n",
    "    return True, \"Research agent already initialized\"\n",
    "\n",
    "# Your HTML template (same as before)\n",
    "HTML_TEMPLATE = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title> Local Research Agent - Powered by Anaconda AI Platform </title>\n",
    "    <style>\n",
    "        * { margin: 0; padding: 0; box-sizing: border-box; }\n",
    "        body {\n",
    "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
    "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "            min-height: 100vh;\n",
    "            padding: 20px;\n",
    "        }\n",
    "        .container {\n",
    "            max-width: 1200px;\n",
    "            margin: 0 auto;\n",
    "            background: white;\n",
    "            border-radius: 15px;\n",
    "            box-shadow: 0 20px 40px rgba(0,0,0,0.1);\n",
    "            overflow: hidden;\n",
    "        }\n",
    "        .header {\n",
    "            background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);\n",
    "            color: white;\n",
    "            padding: 30px;\n",
    "            text-align: center;\n",
    "        }\n",
    "        .header h1 { font-size: 2.5em; margin-bottom: 10px; }\n",
    "        .header p { font-size: 1.1em; opacity: 0.9; }\n",
    "        .main-content { padding: 30px; }\n",
    "        .tabs {\n",
    "            display: flex;\n",
    "            margin-bottom: 30px;\n",
    "            border-bottom: 2px solid #f0f0f0;\n",
    "        }\n",
    "        .tab {\n",
    "            padding: 15px 25px;\n",
    "            cursor: pointer;\n",
    "            border-bottom: 3px solid transparent;\n",
    "            font-weight: 500;\n",
    "            transition: all 0.3s;\n",
    "        }\n",
    "        .tab:hover { background: #f8f9fa; }\n",
    "        .tab.active { border-bottom-color: #667eea; color: #667eea; }\n",
    "        .tab-content { display: none; }\n",
    "        .tab-content.active { display: block; }\n",
    "        .research-form {\n",
    "            background: #f8f9fa;\n",
    "            padding: 25px;\n",
    "            border-radius: 10px;\n",
    "            margin-bottom: 30px;\n",
    "        }\n",
    "        .form-group { margin-bottom: 20px; }\n",
    "        label {\n",
    "            display: block;\n",
    "            margin-bottom: 8px;\n",
    "            font-weight: 600;\n",
    "            color: #333;\n",
    "        }\n",
    "        input[type=\"text\"], textarea, select {\n",
    "            width: 100%;\n",
    "            padding: 12px;\n",
    "            border: 2px solid #e0e0e0;\n",
    "            border-radius: 8px;\n",
    "            font-size: 16px;\n",
    "            transition: border-color 0.3s;\n",
    "        }\n",
    "        input[type=\"text\"]:focus, textarea:focus, select:focus {\n",
    "            outline: none;\n",
    "            border-color: #667eea;\n",
    "        }\n",
    "        .search-btn {\n",
    "            background: linear-gradient(45deg, #667eea, #764ba2);\n",
    "            color: white;\n",
    "            border: none;\n",
    "            padding: 15px 30px;\n",
    "            font-size: 16px;\n",
    "            border-radius: 8px;\n",
    "            cursor: pointer;\n",
    "            transition: transform 0.2s;\n",
    "        }\n",
    "        .search-btn:hover { transform: translateY(-2px); }\n",
    "        .search-btn:disabled { opacity: 0.6; transform: none; cursor: not-allowed; }\n",
    "        .results { margin-top: 30px; }\n",
    "        .result-section {\n",
    "            background: white;\n",
    "            border: 1px solid #e0e0e0;\n",
    "            border-radius: 10px;\n",
    "            padding: 25px;\n",
    "            margin-bottom: 20px;\n",
    "            line-height: 1.6;\n",
    "        }\n",
    "        .result-section h3 {\n",
    "            color: #333;\n",
    "            margin-bottom: 20px;\n",
    "            padding-bottom: 10px;\n",
    "            border-bottom: 2px solid #f0f0f0;\n",
    "            font-size: 1.3em;\n",
    "        }\n",
    "        .result-section h4 {\n",
    "            color: #444;\n",
    "            margin-top: 25px;\n",
    "            margin-bottom: 15px;\n",
    "            font-size: 1.1em;\n",
    "            font-weight: 600;\n",
    "        }\n",
    "        .result-section ul {\n",
    "            margin: 15px 0;\n",
    "            padding-left: 40px;\n",
    "        }\n",
    "        .result-section ol {\n",
    "            margin: 15px 0;\n",
    "            padding-left: 40px;\n",
    "        }\n",
    "        .result-section li {\n",
    "            margin-bottom: 12px;\n",
    "            padding-left: 8px;\n",
    "            line-height: 1.7;\n",
    "        }\n",
    "        .result-section ul li {\n",
    "            list-style-type: disc;\n",
    "            list-style-position: outside;\n",
    "        }\n",
    "        .result-section ol li {\n",
    "            list-style-type: decimal;\n",
    "            list-style-position: outside;\n",
    "        }\n",
    "        .result-section ul ul, .result-section ol ul {\n",
    "            margin: 8px 0;\n",
    "            padding-left: 25px;\n",
    "        }\n",
    "        .result-section ul ol, .result-section ol ol {\n",
    "            margin: 8px 0;\n",
    "            padding-left: 25px;\n",
    "        }\n",
    "        .result-section p {\n",
    "            margin-bottom: 15px;\n",
    "            line-height: 1.6;\n",
    "        }\n",
    "        .loading {\n",
    "            text-align: center;\n",
    "            padding: 40px;\n",
    "            color: #666;\n",
    "        }\n",
    "        .spinner {\n",
    "            border: 4px solid #f3f3f3;\n",
    "            border-top: 4px solid #667eea;\n",
    "            border-radius: 50%;\n",
    "            width: 40px;\n",
    "            height: 40px;\n",
    "            animation: spin 2s linear infinite;\n",
    "            margin: 0 auto 20px;\n",
    "        }\n",
    "        @keyframes spin {\n",
    "            0% { transform: rotate(0deg); }\n",
    "            100% { transform: rotate(360deg); }\n",
    "        }\n",
    "        .source-item {\n",
    "            background: #f8f9fa;\n",
    "            padding: 15px;\n",
    "            border-radius: 8px;\n",
    "            margin-bottom: 10px;\n",
    "            border-left: 4px solid #667eea;\n",
    "        }\n",
    "        .source-title {\n",
    "            font-weight: 600;\n",
    "            color: #333;\n",
    "            margin-bottom: 5px;\n",
    "        }\n",
    "        .source-meta {\n",
    "            color: #666;\n",
    "            font-size: 14px;\n",
    "        }\n",
    "        .samples {\n",
    "            background: #e8f4fd;\n",
    "            padding: 20px;\n",
    "            border-radius: 10px;\n",
    "            margin-top: 20px;\n",
    "        }\n",
    "        .samples h4 {\n",
    "            color: #1976d2;\n",
    "            margin-bottom: 15px;\n",
    "        }\n",
    "        .sample-query {\n",
    "            background: white;\n",
    "            padding: 10px 15px;\n",
    "            border-radius: 6px;\n",
    "            margin-bottom: 8px;\n",
    "            cursor: pointer;\n",
    "            transition: background 0.2s;\n",
    "        }\n",
    "        .sample-query:hover {\n",
    "            background: #f0f8ff;\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"container\">\n",
    "        <div class=\"header\">\n",
    "            <h1>Local Research Agent Powered by Anaconda AI Platform </h1>\n",
    "            <p>Powered by Meta-Llama-3-8B-Instruct via Anaconda AI Catalog</p>\n",
    "            <p>Sources: arXiv Academic Papers + Wikipedia | Everything runs locally!</p>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"main-content\">\n",
    "            <div class=\"tabs\">\n",
    "                <div class=\"tab active\" onclick=\"showTab('research')\">🔍 Research</div>\n",
    "                <div class=\"tab\" onclick=\"showTab('status')\">📊 Status</div>\n",
    "                <div class=\"tab\" onclick=\"showTab('history')\">📚 History</div>\n",
    "                <div class=\"tab\" onclick=\"showTab('about')\">ℹ️ About</div>\n",
    "            </div>\n",
    "            \n",
    "            <div id=\"research\" class=\"tab-content active\">\n",
    "                <div class=\"research-form\">\n",
    "                    <div class=\"form-group\">\n",
    "                        <label for=\"query\">Research Query</label>\n",
    "                        <textarea id=\"query\" rows=\"3\" placeholder=\"Enter your research question (e.g., 'machine learning transformers', 'renewable energy benefits')\"></textarea>\n",
    "                    </div>\n",
    "                    \n",
    "                    <div class=\"form-group\">\n",
    "                        <label for=\"maxSources\">Maximum Sources</label>\n",
    "                        <select id=\"maxSources\">\n",
    "                            <option value=\"3\">3 sources</option>\n",
    "                            <option value=\"5\" selected>5 sources</option>\n",
    "                            <option value=\"7\">7 sources</option>\n",
    "                            <option value=\"10\">10 sources</option>\n",
    "                        </select>\n",
    "                    </div>\n",
    "                    \n",
    "                    <button class=\"search-btn\" onclick=\"startResearch()\">Start Research</button>\n",
    "                </div>\n",
    "                \n",
    "                <div class=\"samples\">\n",
    "                    <h4>Sample Queries</h4>\n",
    "                    <div class=\"sample-query\" onclick=\"setQuery('machine learning transformers')\">Academic: \"machine learning transformers\"</div>\n",
    "                    <div class=\"sample-query\" onclick=\"setQuery('quantum computing algorithms')\">Science: \"quantum computing algorithms\"</div>\n",
    "                    <div class=\"sample-query\" onclick=\"setQuery('renewable energy benefits')\">General: \"renewable energy benefits\"</div>\n",
    "                    <div class=\"sample-query\" onclick=\"setQuery('artificial intelligence ethics')\">Technology: \"artificial intelligence ethics\"</div>\n",
    "                </div>\n",
    "                \n",
    "                <div id=\"results\" class=\"results\"></div>\n",
    "            </div>\n",
    "            \n",
    "            <div id=\"status\" class=\"tab-content\">\n",
    "                <div class=\"result-section\">\n",
    "                    <h3>📊 System Status</h3>\n",
    "                    <div id=\"statusContent\">Click \"Refresh Status\" to check system status...</div>\n",
    "                    <br>\n",
    "                    <button class=\"search-btn\" onclick=\"checkStatus()\">🔄 Refresh Status</button>\n",
    "                </div>\n",
    "            </div>\n",
    "            \n",
    "            <div id=\"history\" class=\"tab-content\">\n",
    "                <div class=\"result-section\">\n",
    "                    <h3>📚 Research History</h3>\n",
    "                    <div id=\"historyContent\">Click \"Refresh History\" to view past research...</div>\n",
    "                    <br>\n",
    "                    <button class=\"search-btn\" onclick=\"loadHistory()\">🔄 Refresh History</button>\n",
    "                </div>\n",
    "            </div>\n",
    "            \n",
    "            <div id=\"about\" class=\"tab-content\">\n",
    "                <div class=\"result-section\">\n",
    "                    <h3>About Local Research Agent</h3>\n",
    "                    <p>This research agent combines packages from Anaconda's Secure Governance with policy enforcement with local secure models to provide comprehensive research capabilities.</p>\n",
    "                    \n",
    "                    <h4>Anaconda AI Platform Technology Stack</h4>\n",
    "                    <ul>\n",
    "                        <li><strong>Language Model:</strong> Via Anaconda's secure and governed model repository Meta-Llama-3-8B-Instruct (running locally)</li>\n",
    "                        <li><strong>Package and Environment Management:</strong> Enabled by packages with Anaconda Secure Governance</li>\n",
    "                        <li><strong>Academic Search:</strong> arXiv API for scientific papers</li>\n",
    "                        <li><strong>General Knowledge:</strong> Wikipedia API for encyclopedic information</li>\n",
    "                        <li><strong>Interface:</strong> Flask web framework for user-friendly interface</li>\n",
    "                    </ul>\n",
    "                    \n",
    "                    <h4>How It Works</h4>\n",
    "                    <ol>\n",
    "                        <li><strong>Search Phase:</strong> Queries arXiv and Wikipedia for relevant sources</li>\n",
    "                        <li><strong>Analysis Phase:</strong> Your local Llama 3 model evaluates source relevance</li>\n",
    "                        <li><strong>Synthesis Phase:</strong> Generates comprehensive research reports</li>\n",
    "                        <li><strong>Citation Phase:</strong> Creates properly formatted citations</li>\n",
    "                    </ol>\n",
    "                    \n",
    "                    <h4>Privacy & Security</h4>\n",
    "                    <ul>\n",
    "                        <li>Everything runs locally on your machine</li>\n",
    "                        <li>No data sent to external APIs (except for source searching)</li>\n",
    "                        <li>Your queries and results stay private</li>\n",
    "                        <li>No API keys required</li>\n",
    "                    </ul>\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "\n",
    "    <script>\n",
    "        function showTab(tabName) {\n",
    "            const tabs = document.querySelectorAll('.tab-content');\n",
    "            tabs.forEach(tab => tab.classList.remove('active'));\n",
    "            const tabButtons = document.querySelectorAll('.tab');\n",
    "            tabButtons.forEach(button => button.classList.remove('active'));\n",
    "            document.getElementById(tabName).classList.add('active');\n",
    "            event.target.classList.add('active');\n",
    "        }\n",
    "        \n",
    "        function setQuery(query) {\n",
    "            document.getElementById('query').value = query;\n",
    "        }\n",
    "        \n",
    "        async function startResearch() {\n",
    "            const query = document.getElementById('query').value.trim();\n",
    "            const maxSources = document.getElementById('maxSources').value;\n",
    "            const resultsDiv = document.getElementById('results');\n",
    "            const searchBtn = document.querySelector('.search-btn');\n",
    "            \n",
    "            if (!query) {\n",
    "                alert('Please enter a research query');\n",
    "                return;\n",
    "            }\n",
    "            \n",
    "            searchBtn.disabled = true;\n",
    "            searchBtn.textContent = '🔄 Researching...';\n",
    "            resultsDiv.innerHTML = '<div class=\"loading\"><div class=\"spinner\"></div><p>Conducting research on: \"' + query + '\"</p><p>This may take 30-60 seconds...</p></div>';\n",
    "            \n",
    "            try {\n",
    "                const response = await fetch('/research', {\n",
    "                    method: 'POST',\n",
    "                    headers: { 'Content-Type': 'application/json' },\n",
    "                    body: JSON.stringify({ query: query, max_sources: parseInt(maxSources) })\n",
    "                });\n",
    "                \n",
    "                const data = await response.json();\n",
    "                \n",
    "                if (data.success) {\n",
    "                    resultsDiv.innerHTML = '<div class=\"result-section\"><h3>Research Report</h3><div style=\"white-space: pre-wrap;\">' + data.report + '</div></div><div class=\"result-section\"><h3>📚 Sources (' + data.sources.length + ')</h3>' + data.sources.map((source, i) => '<div class=\"source-item\"><div class=\"source-title\">' + (i + 1) + '. ' + source.title + '</div><div class=\"source-meta\">Type: ' + source.source_type + ' | Relevance: ' + source.relevance_score.toFixed(2) + ' | <a href=\"' + source.url + '\" target=\"_blank\">View Source</a></div></div>').join('') + '</div><div class=\"result-section\"><h3>📖 Citations</h3>' + data.citations.map((citation, i) => '<p>' + (i + 1) + '. ' + citation + '</p>').join('') + '</div><div class=\"result-section\"><h3>📊 Research Summary</h3><p><strong>Query:</strong> ' + data.query + '</p><p><strong>Research Time:</strong> ' + data.research_time.toFixed(1) + ' seconds</p><p><strong>Confidence Score:</strong> ' + data.confidence_score.toFixed(2) + '/1.0</p><p><strong>Sources Found:</strong> ' + data.sources.length + '</p></div>';\n",
    "                } else {\n",
    "                    resultsDiv.innerHTML = '<div class=\"result-section\"><h3>❌ Error</h3><p>' + data.error + '</p></div>';\n",
    "                }\n",
    "            } catch (error) {\n",
    "                resultsDiv.innerHTML = '<div class=\"result-section\"><h3>❌ Error</h3><p>Failed to conduct research: ' + error.message + '</p></div>';\n",
    "            } finally {\n",
    "                searchBtn.disabled = false;\n",
    "                searchBtn.textContent = 'Start Research';\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        async function checkStatus() {\n",
    "            const statusDiv = document.getElementById('statusContent');\n",
    "            statusDiv.innerHTML = 'Loading status...';\n",
    "            \n",
    "            try {\n",
    "                const response = await fetch('/status');\n",
    "                const data = await response.json();\n",
    "                statusDiv.innerHTML = '<pre>' + data.status + '</pre>';\n",
    "            } catch (error) {\n",
    "                statusDiv.innerHTML = 'Error loading status: ' + error.message;\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        async function loadHistory() {\n",
    "            const historyDiv = document.getElementById('historyContent');\n",
    "            historyDiv.innerHTML = 'Loading history...';\n",
    "            \n",
    "            try {\n",
    "                const response = await fetch('/history');\n",
    "                const data = await response.json();\n",
    "                historyDiv.innerHTML = '<pre>' + data.history + '</pre>';\n",
    "            } catch (error) {\n",
    "                historyDiv.innerHTML = 'Error loading history: ' + error.message;\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        document.getElementById('query').addEventListener('keydown', function(e) {\n",
    "            if (e.key === 'Enter' && e.ctrlKey) {\n",
    "                startResearch();\n",
    "            }\n",
    "        });\n",
    "    </script>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# Flask routes\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template_string(HTML_TEMPLATE)\n",
    "\n",
    "@app.route('/research', methods=['POST'])\n",
    "def research():\n",
    "    try:\n",
    "        data = request.get_json()\n",
    "        query = data.get('query', '').strip()\n",
    "        max_sources = data.get('max_sources', 5)\n",
    "        \n",
    "        if not query:\n",
    "            return jsonify({'success': False, 'error': 'Query is required'})\n",
    "        \n",
    "        if research_agent is None:\n",
    "            success, msg = initialize_agent()\n",
    "            if not success:\n",
    "                return jsonify({'success': False, 'error': msg})\n",
    "        \n",
    "        loop = asyncio.new_event_loop()\n",
    "        asyncio.set_event_loop(loop)\n",
    "        try:\n",
    "            result = loop.run_until_complete(research_agent.research(query, max_sources=max_sources))\n",
    "        finally:\n",
    "            loop.close()\n",
    "        \n",
    "        return jsonify({\n",
    "            'success': True,\n",
    "            'query': result.query,\n",
    "            'report': result.report,\n",
    "            'sources': [{\n",
    "                'title': s.title,\n",
    "                'url': s.url,\n",
    "                'source_type': s.source_type.title(),\n",
    "                'relevance_score': s.relevance_score\n",
    "            } for s in result.sources],\n",
    "            'citations': result.citations,\n",
    "            'confidence_score': result.confidence_score,\n",
    "            'research_time': result.research_time\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        return jsonify({'success': False, 'error': str(e)})\n",
    "\n",
    "@app.route('/status')\n",
    "def status():\n",
    "    try:\n",
    "        if research_agent is None:\n",
    "            success, msg = initialize_agent()\n",
    "            if not success:\n",
    "                return jsonify({'status': msg})\n",
    "        \n",
    "        status = research_agent.get_model_status()\n",
    "        \n",
    "        status_text = f\"\"\" MODEL STATUS\n",
    "LLM Connected: {'✅ Yes' if status['llm_loaded'] else '❌ No'}\n",
    "Search Available: {'✅ Yes' if status['search_available'] else '❌ No'}\n",
    "\"\"\"\n",
    "        \n",
    "        if status['model_info']:\n",
    "            info = status['model_info']\n",
    "            status_text += f\"\"\"\n",
    "Model: {info.get('model_name', 'Unknown')}\n",
    "API Server: {info.get('api_url', 'Unknown')}\n",
    "Server Type: {info.get('server_type', 'Unknown')}\n",
    "\"\"\"\n",
    "        \n",
    "        return jsonify({'status': status_text})\n",
    "    except Exception as e:\n",
    "        return jsonify({'status': f'Error getting status: {str(e)}'})\n",
    "\n",
    "@app.route('/history')\n",
    "def history():\n",
    "    try:\n",
    "        if research_agent is None:\n",
    "            return jsonify({'history': 'Agent not initialized'})\n",
    "        \n",
    "        history = research_agent.get_research_history()\n",
    "        if not history:\n",
    "            return jsonify({'history': ' No research history yet. Start by asking a question!'})\n",
    "        \n",
    "        history_text = f\" Research History ({len(history)} queries)\\n\\n\"\n",
    "        for i, result in enumerate(history, 1):\n",
    "            history_text += f\"{i}. {result.query}\\n\"\n",
    "            history_text += f\"   Confidence: {result.confidence_score:.2f}\\n\"\n",
    "            history_text += f\"   Sources: {len(result.sources)}\\n\"\n",
    "            history_text += f\"   Time: {result.research_time:.1f}s\\n\\n\"\n",
    "        \n",
    "        return jsonify({'history': history_text})\n",
    "    except Exception as e:\n",
    "        return jsonify({'history': f'Error getting history: {str(e)}'})\n",
    "\n",
    "# Function to launch in Jupyter\n",
    "def launch_jupyter_web_interface(port=7861):\n",
    "    \"\"\"Launch Flask web interface from Jupyter notebook\"\"\"\n",
    "    \n",
    "    print(\" Initializing research agent for web interface...\")\n",
    "    init_success, init_message = initialize_agent()\n",
    "    print(init_message)\n",
    "    \n",
    "    def run_flask():\n",
    "        app.run(host='127.0.0.1', port=port, debug=False, use_reloader=False)\n",
    "    \n",
    "    # Start Flask in background thread\n",
    "    flask_thread = threading.Thread(target=run_flask, daemon=True)\n",
    "    flask_thread.start()\n",
    "    \n",
    "    # Wait for server to start\n",
    "    sleep(2)\n",
    "    \n",
    "    # Open browser automatically\n",
    "    webbrowser.open(f'http://127.0.0.1:{port}')\n",
    "    \n",
    "    print(f\"\\n Web interface launched at: http://127.0.0.1:{port}\")\n",
    "    print(\"Interface is local only - not accessible from internet\") \n",
    "    print(\"The server runs in the background - you can continue using Jupyter\")\n",
    "    print(\"To stop the server, restart the kernel\")\n",
    "    \n",
    "    return flask_thread\n",
    "\n",
    "# Launch the web interface\n",
    "web_thread = launch_jupyter_web_interface(port=7861)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143695ec-ea2f-4edc-9b26-b5443a917d4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda-ai-agent]",
   "language": "python",
   "name": "conda-env-anaconda-ai-agent-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
